import pandas as pd
import xgboost as xgb
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, mean_squared_log_error, roc_auc_score, r2_score
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm



train_data = pd.read_excel("Training Set.xlsx")


test_data = pd.read_excel("Test Set.xlsx")


X_train = train_data.iloc[:, :-1]  
y_train = train_data.iloc[:, -1]   


X_test = test_data.iloc[:, :-1]  
y_test = test_data.iloc[:, -1]  


model = xgb.XGBClassifier()


param_grid = {
    'learning_rate': [0.1, 0.2, 0.3],
    'max_depth': [3, 4, 5],
    'n_estimators': [100, 200, 300]
}


grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=10)
grid_search.fit(X_train, y_train)


best_params = grid_search.best_params_
print("Best parameters:", best_params)


model = xgb.XGBClassifier(**best_params)
model.fit(X_train, y_train)


y_train_pred = model.predict(X_train)
train_accuracy = accuracy_score(y_train, y_train_pred)
print("Train Accuracy:", train_accuracy)


y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Test Accuracy:", accuracy)

train_precision = precision_score(y_train, y_train_pred)
train_recall = recall_score(y_train, y_train_pred)
train_f1 = f1_score(y_train, y_train_pred)
train_mse = mean_squared_error(y_train, y_train_pred)
train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)
train_log_loss = mean_squared_log_error(y_train, y_train_pred)
train_auc_roc = roc_auc_score(y_train, y_train_pred)
train_r2 = r2_score(y_train, y_train_pred)

print("Train Precision:", train_precision)
print("Train Recall:", train_recall)
print("Train F1 Score:", train_f1)
print("Train Mean Squared Error:", train_mse)
print("Train Root Mean Squared Error:", train_rmse)
print("Train Log Loss:", train_log_loss)
print("Train AUC-ROC:", train_auc_roc)
print("Train R-squared:", train_r2)


precision = precision_score(y_test, y_pred)
print("Test Precision:", precision)


recall = recall_score(y_test, y_pred)
print("Test Recall:", recall)


f1 = f1_score(y_test, y_pred)
print("Test F1 Score:", f1)


mse = mean_squared_error(y_test, y_pred)
print("Test Mean Squared Error:", mse)


rmse = mean_squared_error(y_test, y_pred, squared=False)
print("Test Root Mean Squared Error:", rmse)


log_loss = mean_squared_log_error(y_test, y_pred)
print("Test Log Loss:", log_loss)


auc_roc = roc_auc_score(y_test, y_pred)
print("Test AUC-ROC:", auc_roc)


r2 = r2_score(y_test, y_pred)
print("Test R-squared:", r2)


train_results = pd.DataFrame({'Train_Actual_Label': y_train, 'Train_Predicted_Probability': model.predict_proba(X_train)[:, 1]})
test_results = pd.DataFrame({'Test_Actual_Label': y_test, 'Test_Predicted_Probability': model.predict_proba(X_test)[:, 1]})

# 合并训练集和测试集的结果
results = pd.concat([train_results, test_results], axis=1)
# 将结果保存到Excel表格
results.to_excel('XGBoost.xlsx', index=False)
